{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fc1b64a",
   "metadata": {},
   "source": [
    "# Importing packages; setting qpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16552fe",
   "metadata": {},
   "source": [
    "importing and setting dwave-2000q machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca09a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dimod\n",
    "import minorminer\n",
    "import minorminer.layout as mml\n",
    "%matplotlib inline\n",
    "import dwave.inspector\n",
    "import matplotlib as mpl\n",
    "from datetime import datetime\n",
    "from pathlib import Path  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe887599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Advantage Advantage_system6.1 and 2000Q DW_2000Q_6.\n",
      "QPU DW_2000Q_6 was selected.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.cloud.exceptions import *\n",
    "\n",
    "try:\n",
    "    qpu_advantage = DWaveSampler(solver={'topology__type': 'pegasus'},token=\"DEV-5fa1054cd25ed5a94ead77ab54c60e280f772f28\")\n",
    "    qpu_2000q = DWaveSampler(solver={'topology__type': 'chimera'},token=\"DEV-5fa1054cd25ed5a94ead77ab54c60e280f772f28\")\n",
    "    qpus = {'Advantage': qpu_advantage, 'DW-2000Q': qpu_2000q}\n",
    "    print(\"Connected to Advantage {} and 2000Q {}.\".format(qpu_advantage.solver.id, qpu_2000q.solver.id))\n",
    "except SolverNotFoundError:\n",
    "    print(\"Currently a pair of solvers are unavailable for sections comparing QPU technologies. Try those examples later.\")\n",
    "\n",
    "from dwave.system import DWaveSampler\n",
    "# Use a D-Wave system as the sampler\n",
    "sampler = DWaveSampler(solver=dict(topology__type='chimera'),token=\"DEV-5fa1054cd25ed5a94ead77ab54c60e280f772f28\")\n",
    "print(\"QPU {} was selected.\".format(sampler.solver.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e70292",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Unit cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf97929",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setting the chains of the Kagome unit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba35c006",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (1, 5), 4: (10, 15), 7: (130, 135), 10: (137, 141)}\n",
      "{0: [(2, 6), (6, 14)], 2: [(7, 3), (3, 131)], 3: [(9, 12), (12, 20)], 5: [(13, 8), (8, 136)], 6: [(129, 132), (132, 140)], 8: [(133, 128), (128, 256)], 9: [(138, 142), (142, 150)], 11: [(143, 139), (139, 267)]}\n",
      "there are 12 chains (sites) per unit cell\n"
     ]
    }
   ],
   "source": [
    "#making a dictionary of sites and their corresponding 2chains. There are 4 2chains per unit cell\n",
    "sites_2chains={}\n",
    "sites_2chains.update({1:(1,5)})\n",
    "sites_2chains.update({4:(10,15)})\n",
    "sites_2chains.update({7:(130,135)})\n",
    "sites_2chains.update({10:(137,141)})\n",
    "print(sites_2chains)\n",
    "\n",
    "#making a dictionary of sites and their corresponding 3chains. There are 8 3chains per unit cell\n",
    "sites_3chains={}\n",
    "sites_3chains.update({0:[(2,6),(6,14)]})\n",
    "sites_3chains.update({2:[(7,3),(3,131)]})\n",
    "sites_3chains.update({3:[(9,12),(12,20)]})\n",
    "sites_3chains.update({5:[(13,8),(8,136)]})\n",
    "sites_3chains.update({6:[(129,132),(132,140)]})\n",
    "sites_3chains.update({8:[(133,128),(128,256)]})\n",
    "sites_3chains.update({9:[(138,142),(142,150)]})\n",
    "sites_3chains.update({11:[(143,139),(139,267)]})\n",
    "print(sites_3chains)\n",
    "\n",
    "#this is a dictionary of all sites in a unit cell and their corresponding chains\n",
    "sites_allchains={}\n",
    "sites_allchains.update(sites_2chains)\n",
    "sites_allchains.update(sites_3chains)        \n",
    "print(\"there are\", len(sites_allchains), \"chains (sites) per unit cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843727f1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Writing the unit cell as a matrix\n",
    "\n",
    "This includes:\n",
    "2chains denoted by 2\n",
    "3chains denotes by 3\n",
    "intra-unit cell couplings denoted by J\n",
    "\n",
    "These Jij values are not necessarily the values that\n",
    "will be used in the embedding, but rather a way to \n",
    "discern the 3 types of couplings being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a4a03b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'unitcellmatrix' (matrix)\n"
     ]
    }
   ],
   "source": [
    "#chains and couplings within a 2x2 star unit cell\n",
    "\n",
    "J=0.5\n",
    "unitcellmatrix = np.matrix([\n",
    "    [0,  1,2,3,5,6,7,8,9,10,12,13,14,15,20,128,129,130,131,132,133,135,136,137,138,139,140,141,142,143,150,256,267],\n",
    "    [1,  0,0,0,2,0,J,0,0,0, 0, 0, 0, 0, 0, 0,  J,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [2,  0,0,0,J,3,J,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [3,  0,0,0,0,0,3,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [5,  2,J,0,0,0,0,0,0,0, 0, J, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [6,  0,3,0,0,0,0,0,0,0, 0, 0, 3, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [7,  J,J,3,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [8,  0,0,0,0,0,0,0,0,0, 0, 3, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [9,  0,0,0,0,0,0,0,0,0, 3, J, 0, J, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [10, 0,0,0,0,0,0,0,0,0, 0, J, 0, 2, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  J,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [12, 0,0,0,0,0,0,0,3,0, 0, 0, 0, 0, 3, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [13, 0,0,0,J,0,0,3,J,J, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [14, 0,0,0,0,3,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [15, 0,0,0,0,0,0,0,J,2, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [20, 0,0,0,0,0,0,0,0,0, 3, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [128,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0],\n",
    "    [129,J,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  3,  J,  J,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [130,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  J,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [131,0,0,3,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [132,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0],\n",
    "    [133,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 3,  J,  J,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [135,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  J,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  J,  0,  0,  0],\n",
    "    [136,0,0,0,0,0,0,3,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  J,  0,  0,  0,  0,  0,  0],\n",
    "    [137,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  J,  0,  0,  0],\n",
    "    [138,0,0,0,0,0,0,0,0,J, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  J,  3,  J,  0,  0,  0],\n",
    "    [139,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  3],\n",
    "    [140,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  3,  0,  0,  J,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [141,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  2,  J,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [142,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  3,  0,  0],\n",
    "    [143,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  J,  0,  J,  J,  3,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [150,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0],\n",
    "    [256,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "    [267,0,0,0,0,0,0,0,0,0, 0, 0, 0, 0, 0, 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0]\n",
    "])\n",
    "\n",
    "%store unitcellmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781619a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   0   2   1   0   2   5   3   4   3   5   0   4   3   8   6   7   2\n",
      "    6   8   7   5  10   9  11   6  10   9  11   9   8  11]\n",
      " [  1   2   3   5   6   7   8   9  10  12  13  14  15  20 128 129 130 131\n",
      "  132 133 135 136 137 138 139 140 141 142 143 150 256 267]]\n"
     ]
    }
   ],
   "source": [
    "#this is an array that contains the sites that each of the qubits on the first row of the unitcell matrix correspond to\n",
    "#this is to be used for tiled matrices which have the same bond structure but have different qubit numbers\n",
    "sites_qubits=np.array([1,0,2,1,0,2,5,3,4,3,5,0,4,3,8,6,7,2,6,8,7,5,10,9,11,6,10,9,11,9,8,11])\n",
    "\n",
    "l=[]\n",
    "for i in range(1,33):\n",
    "    a=unitcellmatrix[0,i]\n",
    "    l.append(a)\n",
    "\n",
    "l=np.asarray(l)\n",
    "l=l.astype(int)\n",
    "#print(l)\n",
    "\n",
    "sites_qubits=np.row_stack((sites_qubits,l))\n",
    "print(sites_qubits)\n",
    "\n",
    "#now we have an array where the second row is the list of qubits in the unit cell\n",
    "#the first row tells you which site each of those qubits are associated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d42a7d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   5   6   7   8   9  10  12  13  14  15  20 128 129 130 131\n",
      " 132 133 135 136 137 138 139 140 141 142 143 150 256 267]\n",
      "There are 32 qubits per unit cell\n"
     ]
    }
   ],
   "source": [
    "# getting a list of the qubits included in a unit cell. The first row in the big matrix is the list of qubits.\n",
    "unitcellqubits=unitcellmatrix[0]\n",
    "#conoverting to array\n",
    "unitcellqubits=np.asarray(unitcellqubits)\n",
    "#converting from floats to ints\n",
    "unitcellqubits=unitcellqubits.astype(int)\n",
    "unitcellqubits=unitcellqubits[0]\n",
    "#deleting the 0 since it was a placeholder in the big matrix\n",
    "unitcellqubits=np.delete(unitcellqubits,0)\n",
    "print(unitcellqubits)\n",
    "print(\"There are\", len(unitcellqubits), \"qubits per unit cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ccb1a5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Writing a matrix for tiling the unit cell\n",
    "There are \n",
    "3 +x tiling couplings\n",
    "3 -y tiling couplings\n",
    "1 xy coupling\n",
    "per unit cell (different for unit cells on an edge,\n",
    "where there isn't a nearby unit cell to tile to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d617949",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#the +x coupling\n",
    "tilingx = np.matrix([\n",
    "    [0,  15,23,141,149,150,147],\n",
    "    [15, 0, J, 0,  0,  0,  0],\n",
    "    [23, J, 0, 0,  0,  0,  0],\n",
    "    [141,0, 0, 0,  J,  0,  0],\n",
    "    [149,0, 0, J,  0,  0,  0],\n",
    "    [150,0, 0, 0,  0,  0,  J],\n",
    "    [147,0, 0, 0,  0,  J,  0]\n",
    "])\n",
    "#the -y coupling\n",
    "tilingy = np.matrix([\n",
    "    [0,  130,258,137,265,267,270],\n",
    "    [130,0,  J,  0,  0,  0,  0],\n",
    "    [258,J,  0,  0,  0,  0,  0],\n",
    "    [137,0,  0,  0,  J,  0,  0],\n",
    "    [265,0,  0,  J,  0,  0,  0],\n",
    "    [267,0,  0,  0,  0,  0,  J],\n",
    "    [270,0,  0,  0,  0,  J,  0]\n",
    "])\n",
    "#the special -x-y coupling\n",
    "xymatrix = np.matrix([\n",
    "    [0,  272,276],\n",
    "    [272,0,  J],\n",
    "    [276,J,  0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f5bb31",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Getting all of the couplers in the unit cell as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eabbb495",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1.0, 5.0): -2.0, (10.0, 15.0): -2.0, (130.0, 135.0): -2.0, (137.0, 141.0): -2.0}\n",
      "There are 4 2chains per unit cell\n",
      "{(2.0, 6.0): -3.0, (3.0, 7.0): -3.0, (3.0, 131.0): -3.0, (6.0, 14.0): -3.0, (8.0, 13.0): -3.0, (8.0, 136.0): -3.0, (9.0, 12.0): -3.0, (12.0, 20.0): -3.0, (128.0, 133.0): -3.0, (128.0, 256.0): -3.0, (129.0, 132.0): -3.0, (132.0, 140.0): -3.0, (138.0, 142.0): -3.0, (139.0, 143.0): -3.0, (139.0, 267.0): -3.0, (142.0, 150.0): -3.0}\n",
      "There are 16 3chains per unit cell (when split into 2chains)\n",
      "{(1.0, 7.0): -1.0, (1.0, 129.0): -1.0, (2.0, 5.0): -1.0, (2.0, 7.0): -1.0, (5.0, 13.0): -1.0, (9.0, 13.0): -1.0, (9.0, 15.0): -1.0, (10.0, 13.0): -1.0, (10.0, 138.0): -1.0, (129.0, 133.0): -1.0, (129.0, 135.0): -1.0, (130.0, 133.0): -1.0, (135.0, 143.0): -1.0, (136.0, 140.0): -1.0, (137.0, 143.0): -1.0, (138.0, 141.0): -1.0, (138.0, 143.0): -1.0}\n",
      "There are 17 internal couplings per unit cell\n",
      "{(15.0, 23.0): -1.0, (141.0, 149.0): -1.0, (147.0, 150.0): -1.0}\n",
      "There are 3 +x tiling couplings\n",
      "{(130.0, 258.0): -1.0, (137.0, 265.0): -1.0, (267.0, 270.0): -1.0}\n",
      "There are 3 -y tiling couplings\n",
      "{(272.0, 276.0): -1.0}\n",
      "There are 1 xy couplings\n",
      "There are 44 total couplings per unit cell\n"
     ]
    }
   ],
   "source": [
    "#keeping a record of the 2 qubit chains and their coupling values\n",
    "couplings_2chains={}\n",
    "jvalue_2chains=-2.0\n",
    "for i in range(1,unitcellmatrix.shape[0]):\n",
    "    for j in range(1,unitcellmatrix.shape[0]):\n",
    "        if unitcellmatrix[i,j]==2:\n",
    "            index1=i\n",
    "            index2=j\n",
    "            qubit1=unitcellmatrix[i,0]\n",
    "            qubit2=unitcellmatrix[0,j]\n",
    "            list=[qubit1,qubit2]\n",
    "            #this gets rid of repeats. ie, (1,5) and (5,1)\n",
    "            list.sort()\n",
    "            couplings_2chains.update({(list[0],list[1]):jvalue_2chains})\n",
    "print(couplings_2chains)\n",
    "print(\"There are\",len(couplings_2chains),\"2chains per unit cell\")\n",
    "\n",
    "#keeping a record of the 3 qubit chains and their coupling values\n",
    "couplings_3chains={}\n",
    "jvalue_3chains=-3.0\n",
    "for i in range(1,unitcellmatrix.shape[0]):\n",
    "    for j in range(1,unitcellmatrix.shape[0]):\n",
    "        if unitcellmatrix[i,j]==3:\n",
    "            index1=i\n",
    "            index2=j\n",
    "            qubit1=unitcellmatrix[i,0]\n",
    "            qubit2=unitcellmatrix[0,j]\n",
    "            list=[qubit1,qubit2]\n",
    "            #this gets rid of repeats. ie, (2,6) and (6,2)\n",
    "            list.sort()\n",
    "            couplings_3chains.update({(list[0],list[1]):jvalue_3chains})\n",
    "print(couplings_3chains)\n",
    "print(\"There are\",len(couplings_3chains),\"3chains per unit cell (when split into 2chains)\")\n",
    "\n",
    "#keeping a record of the internal couplings and their coupling values\n",
    "couplings_internal={}\n",
    "jvalue_internal=-1.0\n",
    "for i in range(1,unitcellmatrix.shape[0]):\n",
    "    for j in range(1,unitcellmatrix.shape[0]):\n",
    "        if unitcellmatrix[i,j]==J:\n",
    "            index1=i\n",
    "            index2=j\n",
    "            qubit1=unitcellmatrix[i,0]\n",
    "            qubit2=unitcellmatrix[0,j]\n",
    "            list=[qubit1,qubit2]\n",
    "            #this gets rid of repeats. ie, (2,6) and (6,2)\n",
    "            list.sort()\n",
    "            couplings_internal.update({(list[0],list[1]):jvalue_internal})\n",
    "print(couplings_internal)\n",
    "print(\"There are\",len(couplings_internal),\"internal couplings per unit cell\")\n",
    "\n",
    "#keeping a record of the tiling couplings and their coupling values\n",
    "couplings_tilingx={}\n",
    "jvalue_tiling=-1.0\n",
    "for i in range(1,tilingx.shape[0]):\n",
    "    for j in range(1,tilingx.shape[0]):\n",
    "        if tilingx[i,j]==J:\n",
    "            index1=i\n",
    "            index2=j\n",
    "            qubit1=tilingx[i,0]\n",
    "            qubit2=tilingx[0,j]\n",
    "            list=[qubit1,qubit2]\n",
    "            #this gets rid of repeats. ie, (2,6) and (6,2)\n",
    "            list.sort()\n",
    "            couplings_tilingx.update({(list[0],list[1]):jvalue_tiling})\n",
    "print(couplings_tilingx)\n",
    "print(\"There are\",len(couplings_tilingx),\"+x tiling couplings\")\n",
    "\n",
    "couplings_tilingy={}\n",
    "jvalue_tiling=-1.0\n",
    "for i in range(1,tilingy.shape[0]):\n",
    "    for j in range(1,tilingy.shape[0]):\n",
    "        if tilingy[i,j]==J:\n",
    "            index1=i\n",
    "            index2=j\n",
    "            qubit1=tilingy[i,0]\n",
    "            qubit2=tilingy[0,j]\n",
    "            list=[qubit1,qubit2]\n",
    "            #this gets rid of repeats. ie, (2,6) and (6,2)\n",
    "            list.sort()\n",
    "            couplings_tilingy.update({(list[0],list[1]):jvalue_tiling})\n",
    "print(couplings_tilingy)\n",
    "print(\"There are\",len(couplings_tilingy),\"-y tiling couplings\")\n",
    "\n",
    "couplings_xy={}\n",
    "jvalue_tiling=-1.0\n",
    "for i in range(1,xymatrix.shape[0]):\n",
    "    for j in range(1,xymatrix.shape[0]):\n",
    "        if xymatrix[i,j]==J:\n",
    "            index1=i\n",
    "            index2=j\n",
    "            qubit1=xymatrix[i,0]\n",
    "            qubit2=xymatrix[0,j]\n",
    "            list=[qubit1,qubit2]\n",
    "            #this gets rid of repeats. ie, (2,6) and (6,2)\n",
    "            list.sort()\n",
    "            couplings_xy.update({(list[0],list[1]):jvalue_tiling})\n",
    "print(couplings_xy)\n",
    "print(\"There are\",len(couplings_xy),\"xy couplings\")\n",
    "\n",
    "#Dictionary with all chains, internal couplings, and tiling couplings\n",
    "couplings_all_unit={}\n",
    "couplings_all_unit.update(couplings_2chains)\n",
    "couplings_all_unit.update(couplings_3chains)\n",
    "couplings_all_unit.update(couplings_internal)\n",
    "couplings_all_unit.update(couplings_tilingx)\n",
    "couplings_all_unit.update(couplings_tilingy)\n",
    "couplings_all_unit.update(couplings_xy)\n",
    "\n",
    "print(\"There are\",len(couplings_all_unit),\"total couplings per unit cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b979b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Checking all of the couplers in the unit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d19756da",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all couplers in unit cell are good\n"
     ]
    }
   ],
   "source": [
    "#checking if all of the couplers in the unit cell are present in the qpu\n",
    "import termcolor\n",
    "from termcolor import colored\n",
    "\n",
    "if all(coupler in sampler.edgelist for coupler in couplings_all_unit.keys())==True:\n",
    "    print(\"all couplers in unit cell are good\")\n",
    "else:\n",
    "    for coupler in couplings_all_unit.keys():\n",
    "        if coupler in sampler.edgelist:\n",
    "            print(colored(coupler, 'green'), colored('is found in list', 'green'))\n",
    "        else:\n",
    "            print(colored(coupler, 'red'), colored('is not found in list', 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac8046",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Defining matrices for tiling the 1+3 matrices.\n",
    "For each matrix, there is a matrix for tiling right and one for tiling down\n",
    "(8 different tiling matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09c8d6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#this matrix will be added on to the base unit cell matrix to tile to the right (+16)\n",
    "unitcell_plus16 = np.zeros(unitcellmatrix.shape)\n",
    "for i in range(1,unitcellmatrix.shape[0]):\n",
    "    unitcell_plus16[0][i]=16\n",
    "    unitcell_plus16[i][0]=16\n",
    "unitcell_plus16=np.asmatrix(unitcell_plus16)\n",
    "\n",
    "#this matrix will be added on to the base unit cell matrix to tile down (+256)\n",
    "unitcell_plus256 = np.zeros(unitcellmatrix.shape)\n",
    "for i in range(1,unitcellmatrix.shape[0]):\n",
    "    unitcell_plus256[0][i]=256\n",
    "    unitcell_plus256[i][0]=256\n",
    "unitcell_plus256=np.asmatrix(unitcell_plus256)\n",
    "\n",
    "#this matrix will be added on to the base tilingx matrix to tile to the right (+16)\n",
    "tilingx_plus16 = np.zeros(tilingx.shape)\n",
    "for i in range(1,tilingx.shape[0]):\n",
    "    tilingx_plus16[0][i]=16\n",
    "    tilingx_plus16[i][0]=16\n",
    "tilingx_plus16=np.asmatrix(tilingx_plus16)\n",
    "\n",
    "#this matrix will be added on to the base tilingx matrix to tile down (+256)\n",
    "tilingx_plus256 = np.zeros(tilingx.shape)\n",
    "for i in range(1,tilingx.shape[0]):\n",
    "    tilingx_plus256[0][i]=256\n",
    "    tilingx_plus256[i][0]=256\n",
    "tilingx_plus256=np.asmatrix(tilingx_plus256)\n",
    "\n",
    "#this matrix will be added on to the base tilingy matrix to tile to the right (+16)\n",
    "tilingy_plus16 = np.zeros(tilingy.shape)\n",
    "for i in range(1,tilingy.shape[0]):\n",
    "    tilingy_plus16[0][i]=16\n",
    "    tilingy_plus16[i][0]=16\n",
    "tilingy_plus16=np.asmatrix(tilingy_plus16)\n",
    "\n",
    "#this matrix will be added on to the base tilingy matrix to tile down (+256)\n",
    "tilingy_plus256 = np.zeros(tilingy.shape)\n",
    "for i in range(1,tilingy.shape[0]):\n",
    "    tilingy_plus256[0][i]=256\n",
    "    tilingy_plus256[i][0]=256\n",
    "tilingy_plus256=np.asmatrix(tilingy_plus256)\n",
    "\n",
    "#this matrix will be added on to the base xy matrix to tile to the right (+16)\n",
    "xy_plus16 = np.zeros((3,3))\n",
    "for i in range(1,xymatrix.shape[0]):\n",
    "    xy_plus16[0][i]=16\n",
    "    xy_plus16[i][0]=16\n",
    "xy_plus16=np.asmatrix(xy_plus16)\n",
    "\n",
    "#this matrix will be added on to the base xy matrix to tile down (+256)\n",
    "xy_plus256 = np.zeros((3,3))\n",
    "for i in range(1,xymatrix.shape[0]):\n",
    "    xy_plus256[0][i]=256\n",
    "    xy_plus256[i][0]=256\n",
    "xy_plus256=np.asmatrix(xy_plus256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71effbcd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Functions for tiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3972e0a4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Defining a function that tiles any matrix to the right,\n",
    "and one that tiles any matrix down.\n",
    "The functions add the appropriate tiling matrix\n",
    "The output is a tuple of matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f8901a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#function that tiles a unitcell to the right once\n",
    "def tile_right(unitcellmat,tilingmatx,tilingmaty,xymat):\n",
    "    \n",
    "    tileright_unitcell=unitcellmat+unitcell_plus16\n",
    "    tileright_tilingx=tilingmatx+tilingx_plus16\n",
    "    tileright_tilingy=tilingmaty+tilingy_plus16\n",
    "    tileright_xy=xymat+xy_plus16\n",
    "    \n",
    "    return tileright_unitcell,tileright_tilingx,tileright_tilingy,tileright_xy\n",
    "\n",
    "\n",
    "#function that tiles a unitcell down once\n",
    "def tile_down(unitcellmat,tilingmatx,tilingmaty,xymat):\n",
    "    \n",
    "    tiledown_unitcell=unitcellmat+unitcell_plus256\n",
    "    tiledown_tilingx=tilingmatx+tilingx_plus256\n",
    "    tiledown_tilingy=tilingmaty+tilingy_plus256\n",
    "    tiledown_xy=xymat+xy_plus256\n",
    "    \n",
    "    return tiledown_unitcell,tiledown_tilingx,tiledown_tilingy,tiledown_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a7bae",
   "metadata": {
    "hidden": true
   },
   "source": [
    "defining a function that tiles the unit cell to make a NxN lattice.\n",
    "Cuts off dangling tiling couplers at the boundaries\n",
    "Outputs a tuple of:\n",
    "unitcellregistry - list of unit cell matrices\n",
    "tiling(x/y/xy)registry - list of tiling matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f119738b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#NxN tiling: This function tiles in +x direction N-1 times and -y direction N-1 times. \n",
    "#Output is basically a NxN lattice\n",
    "def NxN_tile(N):\n",
    "    #making a registry of unitcells. The first entry is the base unitcell\n",
    "    unitcellregistry=[]\n",
    "    unitcellregistry.append(unitcellmatrix)\n",
    "    #making a registry of x tilings. The first entry is the base tiling\n",
    "    tilingxregistry=[]\n",
    "    tilingxregistry.append(tilingx)\n",
    "    #making a registry of y tilings. The first entry is the base tiling\n",
    "    tilingyregistry=[]\n",
    "    tilingyregistry.append(tilingy)\n",
    "    #making a registry of xy tilings. The first entry is the base tiling\n",
    "    xyregistry=[]\n",
    "    xyregistry.append(xymatrix)\n",
    "    \n",
    "    #notes about tiling.\n",
    "    #unitcell tiles right N-1 times, tiles down N-1 times\n",
    "    #x tiling tiles right N-2 times, y tiling tiles right N-1 times, xy tiling tiles right N-2 times\n",
    "    #x tiling tiles down N-1 times, y tiling tiles down N-2 times, xy tiling tiles down N-2 times\n",
    "    \n",
    "    \n",
    "    #tiling the unit cell to the right N-1 times, and appending the registries with the new tiled matrices\n",
    "    for i in range(N-1):\n",
    "        newmatsright=tile_right(unitcellregistry[i],tilingxregistry[0],tilingyregistry[0],xyregistry[0])\n",
    "        unitcellregistry.append(newmatsright[0])\n",
    "    #tiling the tilingx matrix to the right N-2 times (to cut off the qubits hanging) , and appending the registries with the new tiled matrices\n",
    "    for i in range(N-2):\n",
    "        newmatsright=tile_right(unitcellregistry[0],tilingxregistry[i],tilingyregistry[0],xyregistry[0])\n",
    "        tilingxregistry.append(newmatsright[1])\n",
    "    #tiling the tilingy matrix to the right N-1 times (to cut off the qubits hanging) , and appending the registries with the new tiled matrices\n",
    "    for i in range(N-1):\n",
    "        newmatsright=tile_right(unitcellregistry[0],tilingxregistry[0],tilingyregistry[i],xyregistry[0])\n",
    "        tilingyregistry.append(newmatsright[2])\n",
    "   #tiling the xy matrix to the right N-2 times (to cut off the qubits hanging) , and appending the registries with the new tiled matrices\n",
    "    for i in range(N-2):\n",
    "        newmatsright=tile_right(unitcellregistry[0],tilingxregistry[0],tilingyregistry[0],xyregistry[i])\n",
    "        xyregistry.append(newmatsright[3])\n",
    "    \n",
    "    #Now there is a row of N unit cells in the registries. For each unit cell in this row, we tile down N-1 times.\n",
    "    #a list containing the row to be tiled down. Initialize with 1st row. It will be updated with each iteration\n",
    "    tobetiled_downuc=[]\n",
    "    tobetiled_downx=[]\n",
    "    tobetiled_downy=[]\n",
    "    tobetiled_downxy=[]\n",
    "    \n",
    "    for i in range(len(unitcellregistry)):\n",
    "        tobetiled_downuc.append(unitcellregistry[i])   \n",
    "    for i in range(len(tilingxregistry)):\n",
    "        tobetiled_downx.append(tilingxregistry[i])\n",
    "    for i in range(len(tilingyregistry)):\n",
    "        tobetiled_downy.append(tilingyregistry[i])\n",
    "    for i in range(len(xyregistry)):\n",
    "        tobetiled_downxy.append(xyregistry[i])\n",
    "    \n",
    "    \n",
    "    for i in range(N-1):\n",
    "        newrow=[]\n",
    "        for j in tobetiled_downuc:\n",
    "            #tile down each unit cell in the preceding row\n",
    "            newmatsdownuc=tile_down(j,tilingxregistry[0],tilingyregistry[0],xyregistry[0])\n",
    "            #update the registry with new matrix\n",
    "            unitcellregistry.append(newmatsdownuc[0])\n",
    "            #populate newrow with the new matrices\n",
    "            newrow.append(newmatsdownuc[0])\n",
    "            #update the to be tiled down list to be used in the new iteration\n",
    "            tobetiled_downuc=newrow\n",
    "            \n",
    "    for i in range(N-1):\n",
    "        newrow=[]\n",
    "        for j in tobetiled_downx:\n",
    "            #tile down each tilingx matrix in the preceding row\n",
    "            newmatsdownx=tile_down(unitcellregistry[0],j,tilingyregistry[0],xyregistry[0])\n",
    "            #update the registry with new matrix\n",
    "            tilingxregistry.append(newmatsdownx[1])\n",
    "            #populate newrow with the new matrices\n",
    "            newrow.append(newmatsdownx[1])\n",
    "            #update the to be tiled down list to be used in the new iteration\n",
    "            tobetiled_downx=newrow\n",
    "    \n",
    "    for i in range(N-2):\n",
    "        newrow=[]\n",
    "        for j in tobetiled_downy:\n",
    "            #tile down each tilingy matrix in the preceding row\n",
    "            newmatsdowny=tile_down(unitcellregistry[0],tilingxregistry[0],j,xyregistry[0])\n",
    "            #update the registry with new matrix\n",
    "            tilingyregistry.append(newmatsdowny[2])\n",
    "            #populate newrow with the new matrices\n",
    "            newrow.append(newmatsdowny[2])\n",
    "            #update the to be tiled down list to be used in the new iteration\n",
    "            tobetiled_downy=newrow\n",
    "    \n",
    "    for i in range(N-2):\n",
    "        newrow=[]\n",
    "        for j in tobetiled_downxy:\n",
    "            #tile down each xy matrix in the preceding row\n",
    "            newmatsdownxy=tile_down(unitcellregistry[0],tilingxregistry[0],tilingyregistry[0],j)\n",
    "            #update the registry with new matrix\n",
    "            xyregistry.append(newmatsdownxy[3])\n",
    "            #populate newrow with the new matrices\n",
    "            newrow.append(newmatsdownxy[3])\n",
    "            #update the to be tiled down list to be used in the new iteration\n",
    "            tobetiled_downxy=newrow\n",
    "            \n",
    "    if N==1:\n",
    "        tilingxregistry=[]\n",
    "        tilingyregistry=[]\n",
    "        xyregistry=[]\n",
    "    \n",
    "    return unitcellregistry,tilingxregistry,tilingyregistry,xyregistry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56717e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using sites_qubits from earlier, we create an array that contains arrays of the form of sites_qubits, but for the whole NxN lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0610d2fd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tile_sites_qubits(N):\n",
    "    all_sites_qubits=[]\n",
    "    all_sites_qubits.append(sites_qubits)\n",
    "    \n",
    "    #creating the first row\n",
    "    for i in range(N-1):\n",
    "        row1=all_sites_qubits[i][0]\n",
    "        new_row2=all_sites_qubits[i][1]+16\n",
    "        new_array_right=np.row_stack((row1,new_row2))\n",
    "        all_sites_qubits.append(new_array_right)\n",
    "    \n",
    "    tobetiled_down=[]\n",
    "    for i in range(N):\n",
    "        tobetiled_down.append(all_sites_qubits[i])\n",
    "    \n",
    "    \n",
    "    for i in range(N-1):\n",
    "        \n",
    "        newrow=[]\n",
    "        for j in tobetiled_down:\n",
    "            #tile down each unit cell in the preceding row\n",
    "            row1=j[0]\n",
    "            new_row2=j[1]+256\n",
    "            new_array_down=np.row_stack((row1,new_row2))\n",
    "            \n",
    "            #update the registry with each new matrix\n",
    "            all_sites_qubits.append(new_array_down)\n",
    "        \n",
    "            #populate newrow with the new matrices\n",
    "            newrow.append(new_array_down)\n",
    "            #update the to be tiled down list to be used in the new iteration\n",
    "            tobetiled_down=newrow\n",
    "    \n",
    "    all_sites_qubits=np.asarray(all_sites_qubits)\n",
    "    all_sites_qubits=np.reshape(all_sites_qubits,(N,N,2,32))\n",
    "    \n",
    "    return all_sites_qubits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040cc96f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "dwave machine only likes dictionaries for couplers.\n",
    "defining a function to wrrite all of the couplers as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e0f95a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#a function for defining all of the coupling dictionaries of the form (qubit1,qubit2):jvalue\n",
    "def getcouplings(ucreg,tilregx,tilregy,xyreg,\n",
    "                 jvalue_2chains,jvalue_3chains,jvalue_internal,jvalue_tiling):\n",
    "    \n",
    "    couplings_2chains={}    \n",
    "    couplings_3chains={}   \n",
    "    couplings_internal={}\n",
    "    couplings_tilingx={}\n",
    "    couplings_tilingy={}\n",
    "    couplings_xy={}\n",
    "    \n",
    "#     index_sites = []\n",
    "#     avoid_third_site = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for matrix in ucreg:\n",
    "        #keeping a record of the 2 qubit chains and their coupling values\n",
    "        for i in range(1,unitcellmatrix.shape[0]):\n",
    "            for j in range(1,unitcellmatrix.shape[0]):\n",
    "                if matrix[i,j]==2:\n",
    "                    index1=i\n",
    "                    index2=j\n",
    "                    qubit1=matrix[i,0]\n",
    "                    qubit2=matrix[0,j]\n",
    "                    list=[qubit1,qubit2]\n",
    "                    #this gets rid of repeats. ie, (1,5) and (5,1)\n",
    "                    list.sort()\n",
    "                    couplings_2chains.update({(list[0],list[1]):jvalue_2chains})\n",
    "#                     index_sites.append(list[0])\n",
    "        #keeping a record of the 3 qubit chains and their coupling values\n",
    "        for i in range(1,unitcellmatrix.shape[0]):\n",
    "            for j in range(1,unitcellmatrix.shape[0]):\n",
    "                if matrix[i,j]==3:\n",
    "                    index1=i\n",
    "                    index2=j\n",
    "                    qubit1=matrix[i,0]\n",
    "                    qubit2=matrix[0,j]\n",
    "                    list=[qubit1,qubit2]\n",
    "                    #this gets rid of repeats. ie, (2,6) and (6,2)\n",
    "                    list.sort()\n",
    "                    couplings_3chains.update({(list[0],list[1]):jvalue_3chains})\n",
    "#                     if list[0] not in avoid_third_site:\n",
    "#                         index_sites.append(list[0])\n",
    "#                     avoid_third_site.append(list[1], list[0])\n",
    "        #keeping a record of the internal couplings and their coupling values\n",
    "        for i in range(1,unitcellmatrix.shape[0]):\n",
    "            for j in range(1,unitcellmatrix.shape[0]):\n",
    "                if matrix[i,j]==J:\n",
    "                    index1=i\n",
    "                    index2=j\n",
    "                    qubit1=matrix[i,0]\n",
    "                    qubit2=matrix[0,j]\n",
    "                    list=[qubit1,qubit2]\n",
    "                    #this gets rid of repeats. ie, (2,6) and (6,2)\n",
    "                    list.sort()\n",
    "                    couplings_internal.update({(list[0],list[1]):jvalue_internal})\n",
    "        \n",
    "        \n",
    "        \n",
    "    for matrix in tilregx:\n",
    "        #keeping a record of the x tiling couplings and their coupling values\n",
    "        for i in range(1,tilingx.shape[0]):\n",
    "            for j in range(1,tilingx.shape[0]):\n",
    "                if matrix[i,j]==J:\n",
    "                    index1=i\n",
    "                    index2=j\n",
    "                    qubit1=matrix[i,0]\n",
    "                    qubit2=matrix[0,j]\n",
    "                    list=[qubit1,qubit2]\n",
    "                    #this gets rid of repeats. ie, (2,6) and (6,2)\n",
    "                    list.sort()\n",
    "                    couplings_tilingx.update({(list[0],list[1]):jvalue_tiling})\n",
    "                    \n",
    "                    \n",
    "    for matrix in tilregy:\n",
    "        #keeping a record of the y tiling couplings and their coupling values\n",
    "        for i in range(1,tilingy.shape[0]):\n",
    "            for j in range(1,tilingy.shape[0]):\n",
    "                if matrix[i,j]==J:\n",
    "                    index1=i\n",
    "                    index2=j\n",
    "                    qubit1=matrix[i,0]\n",
    "                    qubit2=matrix[0,j]\n",
    "                    list=[qubit1,qubit2]\n",
    "                    #this gets rid of repeats. ie, (2,6) and (6,2)\n",
    "                    list.sort()\n",
    "                    couplings_tilingy.update({(list[0],list[1]):jvalue_tiling})\n",
    "                    \n",
    "                    \n",
    "    \n",
    "    for matrix in xyreg:\n",
    "        #keeping a record of the xy couplings and their coupling values\n",
    "        for i in range(1,xymatrix.shape[0]):\n",
    "            for j in range(1,xymatrix.shape[0]):\n",
    "                if matrix[i,j]==J:\n",
    "                    index1=i\n",
    "                    index2=j\n",
    "                    qubit1=matrix[i,0]\n",
    "                    qubit2=matrix[0,j]\n",
    "                    list=[qubit1,qubit2]\n",
    "                    #this gets rid of repeats. ie, (2,6) and (6,2)\n",
    "                    list.sort()\n",
    "                    couplings_xy.update({(list[0],list[1]):jvalue_tiling})\n",
    "                    \n",
    "\n",
    "    #Dictionary with all chains, internal couplings, and tiling couplings\n",
    "    all_couple_values={}\n",
    "    all_couple_values.update(couplings_2chains)\n",
    "    all_couple_values.update(couplings_3chains)\n",
    "    all_couple_values.update(couplings_internal)\n",
    "    all_couple_values.update(couplings_tilingx)\n",
    "    all_couple_values.update(couplings_tilingy)\n",
    "    all_couple_values.update(couplings_xy)\n",
    "    \n",
    "    \n",
    "    #print(couplings_2chains)\n",
    "    print(\"There are\",len(couplings_2chains),\"2chains\")\n",
    "    \n",
    "    #print(couplings_3chains)\n",
    "    print(\"There are\",len(couplings_3chains),\"3chains (when split into 2chains)\")\n",
    "            \n",
    "    #print(couplings_internal)\n",
    "    print(\"There are\",len(couplings_internal),\"internal couplings\")\n",
    "    \n",
    "    #print(couplings_tilingx)\n",
    "    print(\"There are\",len(couplings_tilingx),\"x tiling couplings\")\n",
    "    \n",
    "    #print(couplings_tilingy)\n",
    "    print(\"There are\",len(couplings_tilingy),\"y tiling couplings\")\n",
    "    \n",
    "    #print(couplings_xy)\n",
    "    print(\"There are\",len(couplings_xy),\"xy couplings\")\n",
    "    \n",
    "    #print(all_couple_values)\n",
    "    print(\"There are\",len(all_couple_values),\"total couplings\")\n",
    "    \n",
    "    return all_couple_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20da77f9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setting N and J, running tiling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24547bde",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Running tiling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eaaacc7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#setting N and J values\n",
    "Num=7\n",
    "j2=-2.0\n",
    "j3=-3.0\n",
    "jint=-1\n",
    "jtil=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d501c82",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "registries=NxN_tile(Num)\n",
    "all_sites_qubits=tile_sites_qubits(Num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "818d3384",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 196 2chains\n",
      "There are 784 3chains (when split into 2chains)\n",
      "There are 833 internal couplings\n",
      "There are 126 x tiling couplings\n",
      "There are 126 y tiling couplings\n",
      "There are 36 xy couplings\n",
      "There are 2101 total couplings\n"
     ]
    }
   ],
   "source": [
    "couplers=getcouplings(\n",
    "    registries[0],registries[1],registries[2],registries[3],\n",
    "j2,j3,jint,jtil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf7c4be",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Functions for: checking all qubits, deleting sites with missing qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eccab919",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#checking nodes and making a list of missing ones\n",
    "def check_nodes(nodlist):\n",
    "    missingqs=[]\n",
    "    if all(qubit in sampler.nodelist for qubit in nodlist)==True:\n",
    "        print(\"all nodes are good\")\n",
    "    else:\n",
    "        for node in nodlist:\n",
    "            if node not in sampler.nodelist:\n",
    "                missingqs.append(node)\n",
    "                print(colored(node, 'red'), colored('is not found in list', 'red'))\n",
    "    return missingqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3363e1fd",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_oldcouplers(oldcoups,oldtups):    \n",
    "    oldinttillist=[]\n",
    "    old2chainslist=[]\n",
    "    old3chainslistpairs=[]\n",
    "\n",
    "    for i in range(len(oldtups)):\n",
    "        tupl=oldtups[i]\n",
    "        if (oldcoups[tupl]==jint):\n",
    "            oldinttillist.append(tupl)\n",
    "        if (oldcoups[tupl]==jtil):\n",
    "            oldinttillist.append(tupl)\n",
    "        if oldcoups[tupl]==j2:\n",
    "            old2chainslist.append(tupl)\n",
    "        if oldcoups[tupl]==j3:\n",
    "            old3chainslistpairs.append(tupl)\n",
    "\n",
    "    #writing 3chains as triplets, and keeping a record of the two pairs that each triplet corresponds to\n",
    "    iset = set([frozenset(s) for s in old3chainslistpairs])  # Convert to a set of sets\n",
    "    result = []\n",
    "    result_pair = []\n",
    "    while(iset):                  # While there are sets left to process:\n",
    "        nset = set(iset.pop())      # Pop a new set\n",
    "        nset_pair = tuple(nset)\n",
    "        check = len(iset)           # Does iset contain more sets\n",
    "        while check:                # Until no more sets to check:\n",
    "            check = False\n",
    "            for s in iset.copy():       # For each other set:\n",
    "                if nset.intersection(s):  # if they intersect:\n",
    "                    check = True            # Must recheck previous sets\n",
    "                    result_pair.append([nset_pair, tuple(s)])\n",
    "                    iset.remove(s)          # Remove it from remaining sets\n",
    "                    nset.update(s)          # Add it to the current set\n",
    "        result.append(tuple(nset))  # Convert back to a list of tuples\n",
    "    old3chainslist=result\n",
    "\n",
    "    return oldinttillist,old2chainslist,old3chainslist,result_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "156af4a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def to_remove(missingqs,oldinttillist,old2chainslist,old3chainslist,result_pair):\n",
    "    #make lists of all 3chains, 2chains, and inttils to remove\n",
    "    remove3chains=[]\n",
    "    remove3chains_pairs = []\n",
    "    remove2chains=[]\n",
    "    removeinttil=[]\n",
    "    for i in range(len(missingqs)):\n",
    "        missq = missingqs[i]\n",
    "\n",
    "        #for each missq, check if it's in a 2chain or 3chain\n",
    "        for i, tup3chain in enumerate(old3chainslist):\n",
    "            if (tup3chain[0] == missq or tup3chain[1] == missq\n",
    "                    or tup3chain[2] == missq):\n",
    "                chain=tup3chain\n",
    "                remove3chains.append(chain)\n",
    "\n",
    "        for i, tup2chain in enumerate(old2chainslist):\n",
    "            if (tup2chain[0] == missq or tup2chain[1] == missq):\n",
    "                chain=tup2chain\n",
    "                remove2chains.append(chain)\n",
    "\n",
    "        #identify all internal/tiling couplings assoociated with the chain\n",
    "        for qubit in chain:\n",
    "            for i, tupinttil in enumerate(oldinttillist):\n",
    "                if (tupinttil[0] == qubit or tupinttil[1] == qubit):\n",
    "                    removeinttil.append(tupinttil)\n",
    "\n",
    "    #remove repeats in removeinttil\n",
    "    removeinttilnew=[]\n",
    "    removeinttil=set(removeinttil)\n",
    "    for tup in removeinttil:\n",
    "        removeinttilnew.append(tup)\n",
    "    removeinttil=removeinttilnew\n",
    "\n",
    "\n",
    "    #remove3chains is a list of triplets. have to convert into pairs\n",
    "    for i in range(len(remove3chains)):\n",
    "        triplet=remove3chains[i]\n",
    "        for j in range(len(old3chainslist)):\n",
    "            if old3chainslist[j]==triplet:\n",
    "                pairs=result_pair[j]\n",
    "                for pair in pairs:\n",
    "                    remove3chains_pairs.append(pair)\n",
    "\n",
    "    #combining the remove lists\n",
    "    allremove=[]\n",
    "    for tup in remove3chains_pairs:\n",
    "        allremove.append(tup)\n",
    "    for tup in remove2chains:\n",
    "        allremove.append(tup)\n",
    "    for tup in removeinttil:\n",
    "        allremove.append(tup)\n",
    "    \n",
    "    return allremove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4821b9d4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Reverse(tuples):\n",
    "    new_tup = tuples[::-1]\n",
    "    return new_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54d36a4b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_couplers(couplerlist,oldtups,allremove):\n",
    "    #removing the couplers from the master couplers list\n",
    "    print(len(couplerlist), \"couplers before\")\n",
    "    for tup in allremove:\n",
    "        if tup in oldtups:\n",
    "            print(tup, \"is good, removing from couplers\")\n",
    "            couplerlist.pop(tup)\n",
    "        else:\n",
    "            print(tup,\"is bad\")\n",
    "            if Reverse(tup) in oldtups:\n",
    "                print(Reverse(tup),\"is good, removing from couplers\")\n",
    "                couplerlist.pop(Reverse(tup))\n",
    "            else:\n",
    "                print(\"what the\")\n",
    "\n",
    "    #extracting tuples from coupler dictionary\n",
    "    newtuples_only=[]\n",
    "    for edge in couplerlist.keys():\n",
    "        newtuples_only.append(edge)\n",
    "\n",
    "    print(len(couplerlist), \"couplers after\")\n",
    "    \n",
    "    #recheck tuples\n",
    "    if all(edge in sampler.edgelist for edge in newtuples_only)==True:\n",
    "        print(\"all couplers are good\")\n",
    "    \n",
    "    return couplerlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d88c4b",
   "metadata": {},
   "source": [
    "# Old flux calibration functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82940650",
   "metadata": {},
   "source": [
    "This function first sets all Ji and hi to zero for the embedding. \n",
    "It anneals the qubits used, given an anneal schedule (modify the anneal schedule as needed),\n",
    "and a list of flux bias offsets.\n",
    "Outputs mi, the magnetization of qubit i, averaged over all reads.\n",
    "This function is called through the flux bias offset calibration's iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4452287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qub_mags(hifluxl,Nreads,sstar):\n",
    "    hdict={}\n",
    "    hbias=[0]*sampler.properties['num_qubits']\n",
    "    for j in range(len(hifluxl)):\n",
    "        hbias[int(newnodes[j])]=hifluxl[j]\n",
    "        hdict.update({newnodes[j]:0})\n",
    "    \n",
    "    ann_sch=[[0.0,0.0],[(100*sstar),sstar],[(100.0*sstar)+10.0,sstar],[(100.0*sstar)+10.0+1.0-sstar,1.0]]\n",
    "        \n",
    "    resp = sampler.sample_ising(\n",
    "        h=hdict,J={},num_reads=Nreads,\n",
    "        flux_drift_compensation=False,\n",
    "        flux_biases=hbias,\n",
    "        anneal_schedule=ann_sch\n",
    "    )\n",
    "             \n",
    "    #number of runs in resp\n",
    "    Nruns=resp.record.shape[0]\n",
    "    #make a list of qubits used\n",
    "    qubitl=[]\n",
    "    for qubit in resp.variables:\n",
    "        qubitl.append(qubit)\n",
    "    #calculate the magnetization of each qubit over all runs\n",
    "    #and make a magnetization list\n",
    "    magl=[]\n",
    "    for i in range(len(qubitl)):\n",
    "        #list of spins from all runs for qubiti\n",
    "        spinl=[]\n",
    "        for run in range(Nruns):\n",
    "            spin=resp.record[run][0][i]\n",
    "            spinl.append(spin)\n",
    "        avgspin=(sum(spinl))/(len(spinl))\n",
    "        magl.append(avgspin)\n",
    "        \n",
    "    qm_ar=np.array([qubitl,magl])\n",
    "    #this is the magnetization, averaged first over all runs for individual sites,\n",
    "    #and then averaged over all sites\n",
    "    avg_m=np.mean(qm_ar[1])\n",
    "    stdev_m=np.std(qm_ar[1])\n",
    "\n",
    "    \n",
    "#     dwave.inspector.show(resp)\n",
    "    \n",
    "    return qm_ar,avg_m,stdev_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34d43df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5e-06"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=float(5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69b59612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binsearch(hiup_l,hidown_l,Nreads,Nrep,sstar):\n",
    "    print(\"avg of inputted hiup is\", np.mean(hiup_l))\n",
    "    print(\"avg of inputted hidown is\", np.mean(hidown_l))\n",
    "\n",
    "    \n",
    "    check1=True\n",
    "    count=0\n",
    "    while check1:\n",
    "        q_mags=qub_mags(hiup_l,Nreads,sstar)\n",
    "        if q_mags[1]>0.5:\n",
    "            check1=False\n",
    "        hiup_l=hiup_l*2\n",
    "        print(count,\"avg mag=\",q_mags[1])\n",
    "        count+=1\n",
    "    print(\"done setting hiups\")\n",
    "    print(\"avg hiup is\", np.mean(hiup_l))\n",
    "    print(\"\")\n",
    "    \n",
    "    check2=True\n",
    "    count=0\n",
    "    while check2:\n",
    "        q_mags=qub_mags(hidown_l,Nreads,sstar)\n",
    "        if q_mags[1]<-0.5:\n",
    "            check2=False\n",
    "        hidown_l=hidown_l*2\n",
    "        print(count,\"avg mag=\",q_mags[1])\n",
    "        count+=1\n",
    "    print(\"done setting hidowns\")\n",
    "    print(\"avg hidown is\", np.mean(hidown_l))\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    Nqu=len(q_mags[0][1])\n",
    "    hifluxl=(1/2)*(hiup_l+hidown_l)\n",
    "    print(\"initial avg of hiflux is\", np.mean(hifluxl))\n",
    "    print(\"\")\n",
    "    \n",
    "    for rep in range(Nrep):\n",
    "        pivotl=(1/2)*(hiup_l+hidown_l)\n",
    "        print(\"current avg pivot is\", np.mean(pivotl))\n",
    "        q_mags=qub_mags(pivotl,Nreads,sstar)\n",
    "\n",
    "        for i in range(Nqu):\n",
    "            if q_mags[0][1][i]>0:\n",
    "                hiup_l[i]=pivotl[i]\n",
    "            if q_mags[0][1][i]<0:\n",
    "                hidown_l[i]=pivotl[i]\n",
    "        print(\"done with rep\",rep)\n",
    "        print(\"current avg mag\", q_mags[1])\n",
    "        print(\"current mag stdev\", np.std(q_mags[0][1]))\n",
    "        print(\"\")\n",
    "                \n",
    "    hifluxl=(1/2)*(hiup_l+hidown_l)\n",
    "    print(\"avg hiflux is\",np.mean(hifluxl))\n",
    "    variance=np.abs(hiup_l-hidown_l)\n",
    "    \n",
    "    return hifluxl,variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01ed3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phimax=sampler.properties['anneal_offset_step_phi0']\n",
    "# hiuptest=0.1*phimax*np.ones(len(nodes))\n",
    "# hidowntest=-0.1*phimax*np.ones(len(nodes))\n",
    "# test=binsearch(hiuptest,hidowntest,1.0)\n",
    "# #hflx is the list of hiflux values\n",
    "# hflx=test[0]\n",
    "# hflxmean=np.mean(hflx[0])\n",
    "# print(hflxmean)\n",
    "# hflxstdev=np.std(hflx[0])\n",
    "# print(hflxstdev)\n",
    "\n",
    "# h={}\n",
    "# J=couplers\n",
    "# hbias=[0]*sampler.properties['num_qubits']\n",
    "# for j in range(len(hflx)):\n",
    "#     hbias[int(nodes[j])]=hflx[j]\n",
    "# response = sampler.sample_ising(h, J, num_reads=100,flux_drift_compensation=False,\n",
    "#                                flux_biases=hbias)\n",
    "\n",
    "# print(response)\n",
    "# dwave.inspector.show(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb48c87",
   "metadata": {},
   "source": [
    "# New flux calibration functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0deaa9",
   "metadata": {},
   "source": [
    "This new flux calibration routine is based on \"Coherent quantum annealing in 2000 qubit chain\" - King et al"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ca5682",
   "metadata": {},
   "source": [
    "The same qub mags function is used for the new flux calibration routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "233ff1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nrep is repetitions of calibration\n",
    "#Nreads is anneals per repetition\n",
    "def new_flux_cal(mi_init,hifluxl_init,alpha,Nrep,Nreads,sstar):\n",
    "    \n",
    "    #intialize the lists of mi and hiflux\n",
    "    #for the first run this will be \n",
    "    mi=mi_init\n",
    "    hifluxl=hifluxl_init\n",
    "    \n",
    "    flux_list_Nrep=[]\n",
    "    mi_list_Nrep=[]\n",
    "    \n",
    "    for count in range(Nrep):\n",
    "        q_mags=qub_mags(hifluxl,Nreads,sstar)\n",
    "        mi=q_mags[0][1]\n",
    "        \n",
    "        flux_list_Nrep.append(hifluxl)\n",
    "        mi_list_Nrep.append(mi)\n",
    "        \n",
    "        hifluxl=hifluxl-alpha*mi\n",
    "\n",
    "    return flux_list_Nrep,mi_list_Nrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee8a40",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Document name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a8ede77",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def DocName(jvalue_internal,Num):\n",
    "    str1=str(Num)\n",
    "    \n",
    "    str2=\"J=\"+str(jvalue_internal)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    str3 = now.strftime(\"%m-%d-%y__%H-%M-%S\")\n",
    "    \n",
    "    Documentname=str1+\"x\"+str1+\"Kagome\"+str2+\"__\"+str3+\".csv\"\n",
    "    \n",
    "    return Documentname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6e330",
   "metadata": {},
   "source": [
    "# Annealing with new flux calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f04dca1",
   "metadata": {},
   "source": [
    "qpu annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd5b825f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are the base couplers that we want to embed\n",
      "There are 196 2chains\n",
      "There are 784 3chains (when split into 2chains)\n",
      "There are 833 internal couplings\n",
      "There are 126 x tiling couplings\n",
      "There are 126 y tiling couplings\n",
      "There are 36 xy couplings\n",
      "There are 2101 total couplings\n",
      "\n",
      "there are 1568 nodes\n",
      "these are the missing qubits\n",
      "\u001b[31m46.0\u001b[0m \u001b[31mis not found in list\u001b[0m\n",
      "\u001b[31m524.0\u001b[0m \u001b[31mis not found in list\u001b[0m\n",
      "\u001b[31m548.0\u001b[0m \u001b[31mis not found in list\u001b[0m\n",
      "\u001b[31m1723.0\u001b[0m \u001b[31mis not found in list\u001b[0m\n",
      "\u001b[31m1735.0\u001b[0m \u001b[31mis not found in list\u001b[0m\n",
      "\n",
      "these are the base couplers that we want to embed, again\n",
      "There are 196 2chains\n",
      "There are 784 3chains (when split into 2chains)\n",
      "There are 833 internal couplings\n",
      "There are 126 x tiling couplings\n",
      "There are 126 y tiling couplings\n",
      "There are 36 xy couplings\n",
      "There are 2101 total couplings\n",
      "\n",
      "these are the couplers we want to remove\n",
      "[(34.0, 38.0), (46.0, 38.0), (524.0, 532.0), (521.0, 524.0), (540.0, 548.0), (537.0, 540.0), (1723.0, 1727.0), (1851.0, 1723.0), (1730.0, 1735.0), (521.0, 525.0), (409.0, 537.0), (393.0, 521.0), (1719.0, 1727.0), (537.0, 541.0), (1722.0, 1727.0), (1735.0, 1743.0), (1730.0, 1733.0), (537.0, 543.0), (34.0, 39.0), (521.0, 527.0), (1729.0, 1735.0), (1721.0, 1727.0), (34.0, 37.0), (544.0, 548.0), (528.0, 532.0)]\n",
      "\n",
      "2101 couplers before\n",
      "(34.0, 38.0) is good, removing from couplers\n",
      "(46.0, 38.0) is bad\n",
      "(38.0, 46.0) is good, removing from couplers\n",
      "(524.0, 532.0) is good, removing from couplers\n",
      "(521.0, 524.0) is good, removing from couplers\n",
      "(540.0, 548.0) is good, removing from couplers\n",
      "(537.0, 540.0) is good, removing from couplers\n",
      "(1723.0, 1727.0) is good, removing from couplers\n",
      "(1851.0, 1723.0) is bad\n",
      "(1723.0, 1851.0) is good, removing from couplers\n",
      "(1730.0, 1735.0) is good, removing from couplers\n",
      "(521.0, 525.0) is good, removing from couplers\n",
      "(409.0, 537.0) is good, removing from couplers\n",
      "(393.0, 521.0) is good, removing from couplers\n",
      "(1719.0, 1727.0) is good, removing from couplers\n",
      "(537.0, 541.0) is good, removing from couplers\n",
      "(1722.0, 1727.0) is good, removing from couplers\n",
      "(1735.0, 1743.0) is good, removing from couplers\n",
      "(1730.0, 1733.0) is good, removing from couplers\n",
      "(537.0, 543.0) is good, removing from couplers\n",
      "(34.0, 39.0) is good, removing from couplers\n",
      "(521.0, 527.0) is good, removing from couplers\n",
      "(1729.0, 1735.0) is good, removing from couplers\n",
      "(1721.0, 1727.0) is good, removing from couplers\n",
      "(34.0, 37.0) is good, removing from couplers\n",
      "(544.0, 548.0) is good, removing from couplers\n",
      "(528.0, 532.0) is good, removing from couplers\n",
      "2076 couplers after\n",
      "all couplers are good\n",
      "2076 tuples\n",
      "there are 1554 nodes now\n"
     ]
    }
   ],
   "source": [
    "#setting N and J values (globals)\n",
    "Num=7\n",
    "j2=-2.0\n",
    "j3=-3.0\n",
    "jint=-1.0\n",
    "jtil=-1.0\n",
    "\n",
    "#get the registries and all sites qubits array for the whole NxN lattice\n",
    "registries=NxN_tile(Num)\n",
    "all_sites_qubits=tile_sites_qubits(Num)\n",
    "\n",
    "\n",
    "#this block lets us identify missing qubits and stores them\n",
    "print(\"these are the base couplers that we want to embed\")\n",
    "couplers=getcouplings(\n",
    "    registries[0],registries[1],registries[2],registries[3],\n",
    "j2,j3,jint,jtil)\n",
    "#extracting tuples from coupler dictionary\n",
    "tuples_only=[]\n",
    "for edge in couplers.keys():\n",
    "    tuples_only.append(edge)\n",
    "#extracting nodes being used from the couplers\n",
    "nodes=[]\n",
    "for i in tuples_only:\n",
    "    val0=i[0]\n",
    "    val1=i[1]\n",
    "    nodes.append(val0)\n",
    "    nodes.append(val1)\n",
    "nodes=[*set(nodes)]\n",
    "nodes.sort()\n",
    "print(\"\")\n",
    "print(\"there are\", len(nodes), \"nodes\")\n",
    "print(\"these are the missing qubits\")\n",
    "missingqubits=check_nodes(nodes)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#get the same couplers again to see which couplers we need to remove\n",
    "print(\"these are the base couplers that we want to embed, again\")\n",
    "oldcouplers=getcouplings(\n",
    "    registries[0],registries[1],registries[2],registries[3],\n",
    "j2,j3,jint,jtil)\n",
    "print(\"\")\n",
    "\n",
    "oldtuples=[]\n",
    "oldsets=[]\n",
    "for tupl in oldcouplers.keys():\n",
    "    oldtuples.append(tupl)\n",
    "    oldsets.append(set(tupl))\n",
    "\n",
    "oldinttil=split_oldcouplers(oldcouplers,oldtuples)[0]\n",
    "old2chains=split_oldcouplers(oldcouplers,oldtuples)[1]\n",
    "old3chains=split_oldcouplers(oldcouplers,oldtuples)[2]\n",
    "result_pair=split_oldcouplers(oldcouplers,oldtuples)[3]\n",
    "\n",
    "print(\"these are the couplers we want to remove\")\n",
    "removelist=to_remove(missingqubits,oldinttil,old2chains,old3chains,result_pair)\n",
    "print(removelist)\n",
    "print(\"\")\n",
    "\n",
    "#remove the appropriate couplers before calibration\n",
    "#copy couplers first\n",
    "newbasecouplers=oldcouplers\n",
    "newcouplers=remove_couplers(newbasecouplers,oldtuples,removelist)\n",
    "newtuples=[]\n",
    "for edge in newcouplers.keys():\n",
    "    newtuples.append(edge)\n",
    "print(len(newtuples),\"tuples\")\n",
    "newnodes=[]\n",
    "for tupl in newtuples:\n",
    "    val0=tupl[0]\n",
    "    val1=tupl[1]\n",
    "    newnodes.append(val0)\n",
    "    newnodes.append(val1)\n",
    "newnodes=[*set(newnodes)]\n",
    "newnodes.sort()\n",
    "print(\"there are\",len(newnodes),\"nodes now\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "print(\"running new flux calibration\")\n",
    "#flux calibration\n",
    "#set Nrep for the stages\n",
    "Nrep1=100\n",
    "Nrep2=300\n",
    "Nrep3=400\n",
    "Nrep_total=Nrep1+Nrep2+Nrep3\n",
    "\n",
    "#make a list of all hiflux lists from all iterations\n",
    "all_hiflux=[]\n",
    "#make a list of all mi lists from all iterations\n",
    "all_mi=[]\n",
    "\n",
    "#start by setting all flux bias offsets to 0, and get mi (to be used in very first iteration)\n",
    "zerofluxes=np.zeros(len(newnodes))\n",
    "all_hiflux.append(zerofluxes)\n",
    "mi_zero=qub_mags(zerofluxes)[0][1]\n",
    "all_mi.append(mi_zero)\n",
    "\n",
    "\n",
    "#first stage has 0 flux bias offsets (alpha=0)\n",
    "print(\"doing\",Nrep1,\"iterations of alpha=0\")\n",
    "first_run=new_flux_cal(mi_zero,zerofluxes,alpha=0,Nrep=Nrep1,Nreads=100,sstar=0.2)\n",
    "first_flux_out=first_run[0]\n",
    "first_mi_out=first_run[1]\n",
    "#extract the final list of mi and hiflux to be used in the next stage\n",
    "first_final_flux=first_flux_out[len(first_flux_out)-1]\n",
    "first_final_mi=first_mi_out[len(first_mi_out)-1]\n",
    "\n",
    "all_hiflux.append(first_flux_out)\n",
    "all_mi.append(first_mi_out)\n",
    "print(\"done 1st stage\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#second stage has nonzero alpha\n",
    "print(\"doing\",Nrep2,\"iterations of alpha=5e-6\")\n",
    "second_run=new_flux_cal(first_final_mi,first_final_flux,alpha=5e-6,Nrep=Nrep2,Nreads=100,sstar=0.2)\n",
    "second_flux_out=second_run[0]\n",
    "second_mi_out=second_run[1]\n",
    "#extract the final list of mi and hiflux to be used in the next stage\n",
    "second_final_flux=second_flux_out[len(second_flux_out)-1]\n",
    "second_final_mi=second_mi_out[len(second_mi_out)-1]\n",
    "\n",
    "all_hiflux.append(second_flux_out)\n",
    "all_mi.append(second_mi_out)\n",
    "print(\"done 2nd stage\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#third stage also has nonzero alpha\n",
    "print(\"doing\",Nrep2,\"iterations of alpha=0.2\")\n",
    "third_run=new_flux_cal(second_final_mi,second_final_flux,alpha=0.2,Nrep=Nrep3,Nreads=100,sstar=0.2)\n",
    "third_flux_out=third_run[0]\n",
    "third_mi_out=third_run[1]\n",
    "\n",
    "all_hiflux.append(third_flux_out)\n",
    "all_mi.append(third_mi_out)\n",
    "print(\"done 3rd stage\")\n",
    "print(\"\")\n",
    "\n",
    "#checking the big lists' shape\n",
    "print(\"checking if we have the correct number of values\")\n",
    "print(\"there are\", len(all_hiflux), \"stages in the hiflux list\")\n",
    "print(\"there are\", len(all_mi), \"stages in the mi list\")\n",
    "print(\"\")\n",
    "print(\n",
    "    \"there are,\" len(all_hiflux[0]), len(all_hiflux[1]), len(all_hiflux[2]),\n",
    "                                                             \"hiflux lists in stage 1, 2, and 3\")\n",
    "print(\n",
    "    \"there are,\" len(all_mi[0]), len(all_mi[1]), len(all_mi[2]),\n",
    "                                                             \"mi lists in stage 1, 2, and 3\")\n",
    "\n",
    "#all_hiflux should help us make the hairy plots in King et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df09d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b238a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
